---
dataset_name: imdb
model_name: TransformerClassificationModel
optimizer_name: SGD
epoch: 10
use_amp: true
learning_rate_scheduler_name: CosineAnnealingLR
learning_rate: 0.1
log_level: INFO
cache_transforms: cpu
dataset_kwargs:
  dataset_type: text
  tokenizer:
    type: spacy
dataset_kwargs:
  max_len: 300
model_kwargs:
  max_len: 300
  word_vector_name: glove.6B.100d
  num_encoder_layer: 2
  d_model: 100
  nhead: 5
